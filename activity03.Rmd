---
title: "Activity 3 - MLR"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In the last activity, you might have noticed that I made this Rmd output a document with a type of `github_document` (in the YAML header underneath the title - on line 3) instead of a HTML, Word, or PDF document.
This produces a GitHub friendly Markdown file that GitHub then renders to HTML.
You can read more about this output type in RMarkdown's [documentation page](https://rmarkdown.rstudio.com/github_document_format.html) if you want to learn more.

# Day 1

## Load the necessary packages

I encourage you to continue using the two packages from Posit (formerly [RStudio](https://posit.co/)): `{tidyverse}` and `{tidymodels}`.
Remember that [Emil Hvitfeldt](https://www.emilhvitfeldt.com/) (of Posit) has put together a [complementary online text](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html) for the labs in the *ISLR* text that utilize `{tidyverse}` and `{tidymodels}` instead of base R.

- In the **Packages** pane of RStudio, check if `{tidyverse}` and `{tidymodels}` are installed.
  Be sure to check both your **User Library** and **System Library**.
- If either of these are not currently listed (they should be because you verified this in Activity 1), type the following in your **Console** pane, replacing `package_name` with the appropriate name, and  press Enter/Return afterwards.
  
```{r  eval = FALSE}
  install.packages("package_name")
```
  

- Once you have verified that both `{tidyverse}` and `{tidymodels}` are installed (in either your user or system library), load these packages in the R chunk below titled `load-packages`.
  
- Run the `load-packages` code chunk or **knit** <img src="../README-img/knit-icon.png" alt="knit" width = "20"/> icon your Rmd document to verify that no errors occur.

```{r load-packages}
library(tidyverse)
library(tidymodels)
library(GGally)

theme_set(ggthemes::theme_few())
```

Since we will be looking at many relationships graphically, it will be nice to not have to code each of these individually.
`{GGally}` is an extension to `{ggplot2}` that reduces some of the complexities when combining multiple plots.
For example, [`GGally::ggpairs`](http://ggobi.github.io/ggally/articles/ggpairs.html) is very handy for pairwise comparisons of multiple variables.

- In the **Packages** pane of RStudio, check if `{GGally}` is already installed.
  Be sure to check both your **User Library** and **System Library**.
- If this is not currently listed, type the following in your **Console** pane and  press Enter/Return afterwards.
  
  ```{r  eval = FALSE}
  install.packages("GGally")
  ```
  
- Once you have verified that `{GGally}` is installed, load it in the R chunk titled `load-packages`.
  
- Run the `setup` code chunk or **knit** <img src="../README-img/knit-icon.png" alt="knit" width = "20"/> icon your Rmd document to verify that no errors occur.

## Load the data and

I found a way to upload data from OpenIntro without needing to download it first!
Recall that data we are working with is from the OpenIntro site (its "about" page: https://www.openintro.org/data/index.php?data=hfi).
We can access the raw data from their tab-delimited text file link: https://www.openintro.org/data/tab-delimited/hfi.txt.

Create a new R code chunk below that is titled `load-data` and reads in the above linked TSV (tab-separated values) file by doing the following:

- Rather than downloading this file, uploading to RStudio, then reading it in, explore how to load this file directly from the provided URL with `readr::read_tsv` (`{readr}` is part of `{tidyverse}`).
- Assign this data set into a data frame named `hfi` (short for "Human Freedom Index").
- Filter the data `hfi` data frame for year 2016 and assigns the result to an R data object named `hfi_2016`. You will use `hfi_2016` for the remainder of this activity.

```{r load-data}
# Load the data directly from the URL
hfi <- read.csv("hfi.csv")

# Filter the data for the year 2016
hfi_2016 <- hfi |> filter(year == 2016)
```

Get the characteristics of the dataset

```{r}
# Getting the characteristics of the dataset
glimpse(hfi_2016)
```



We will continue using personal freedom scores, `pf_score`, as the response variable and build on our model that had `pf_expression_control` as the explanatory variable. 

Create a new R code chunk below, with an appropriate title, that does the following:

- Review the about page of the data set and select at least one additional numeric variables (hint: look for `<dbl>` or `<int>` designations) to describe its distribution. Remember to write your description.
- You may also wish to do this for `pf_score` and `pf_expression_control` again to help you remember what you noticed last week.

## Pairwise relationships

In Activity 2 you explored simple linear regression models.
Specifically, you fit and assessed this relationship:

$$
y = \beta_0 + \beta_1 \times x + \varepsilon
$$

```{r Pairwise relationships}
# Select additional numeric variables for analysis

selected_variables <- hfi_2016 %>%
  select(pf_score, pf_expression_control, pf_ss, pf_ss_homicide)

# Summary statistics and distributions of the selected numeric variables
summary(selected_variables)
```


![check-in](../README-img/noun-magnifying-glass.png) **Check in**

Review how you described this model in Activity 2.
  - What were your parameter estimates (i.e., the $\beta$s)?
    How did you interpret these and what did they imply for this scenario?
  - How good of a fit was this model?
    What did you use to assess this?

For this activity, we will begin using the two other quantitative variables to describe the patterns in the response variable.
Take a moment to think about what this previous sentence means:

- What does this mean from a statistical point of view?
- What does this mean from a "real world" point of view (i.e., for your data's situation)?

Now, we will obtain graphical and numerical summaries to describe the pairwise relationships.


- In the code chunk below titled `pairs-plot`, replace "verbatim" with "r" just before the code chunk title.
- Replace `explanatory` in the `select` line with the variable you identified above
- Run your code chunk or knit your document.
  
```{r pairs-plot}
hfi_2016 %>% 
  select(pf_score, pf_expression_control, pf_ss) %>% 
  ggpairs()
```

Note that a warning message (really a list of warning messages) might display in your **Console** and likely under your R code chunk when you knit this report.
In R, warning messages are not necessarily a bad thing and you should read these to make sure you understand what it is informing you of.
To suppress warning messages from displaying after this specific R code chunk when you knit your report, add the follow inside the curly brackets (`{r }`) at the top of your R code chunk (notice the preceding comma): `, warning=FALSE`.

Somewhat related... If you do not want all the messages `{tidyverse}` and `{tidymodels}` produce when you load them, you can add `, message=FALSE` to your `load-packages` R code chunk.

After running the `pairs-plot` code, answer the following questions:

1. For each pair of variables, how would you describe the relationship graphically?
  Do any of the relationships look linear?
  Are there any interesting/odd features (outliers, non-linear patterns, etc.)?

*a) pf_score vs pf_expression_control:*
*The relationship appears to be roughly linear, with a positive correlation. There are no obvious outliers or non-linear patterns.*

*b) pf_score vs pf_ss:*
*The relationship also appears to be linear, with a positive correlation. There are no obvious outliers or non-linear patterns.*

*c) pf_expression_control vs pf_ss:*
*The relationship seems to be linear, with a positive correlation. There are no obvious outliers or non-linear patterns.*


2. For each pair of variables, how would you describe the relationship numerically?
*a) pf_score vs pf_expression_control:*
*The correlation coefficient is 0.845, indicating a strong positive linear relationship between the variables.*

*b) pf_score vs pf_ss:*
*The correlation coefficient is 0.753, indicating a moderately strong positive linear relationship between the variables.*

*c) pf_expression_control vs pf_ss:*
*The correlation coefficient is 0.546, indicating a moderate positive linear relationship between the variables.*

3. Are your two explanatory variables collinear (correlated)?
  Essentially, this means that adding more than one of these variables to the model would not add much value to the model.
  We will talk more on this issue in Activity 4 (other considerations in regression models).

*The explanatory variables in this case are pf_expression_control and pf_ss. The correlation coefficient between these two variables is 0.546, which indicates a moderate positive relationship. This suggests that the two explanatory variables are not strongly collinear, and adding both of them to a regression model would likely provide additional information beyond using just one of the variables.*


## The multiple linear regression model

You will now fit the following model:

$$
y = \beta_0 + \beta_1 \times x_1 + \beta_2 \times x_2 + \varepsilon
$$


- In the code chunk below titled `mlr-model`, replace "verbatim" with "r" just before the code chunk title.
- Replace `explanatory`, similarly to what you did in your `pairs-plot` R code chunk.
- Run your code chunk or knit your document.
  
```{r mlr-model}
#fit the mlr model
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

lm_spec

mlr_mod <- lm_spec %>% 
fit(pf_score ~ pf_expression_control + pf_ss, data = hfi_2016)

# model output
tidy(mlr_mod)
```

After doing this, answer the following questions:

4. Using your output, write the complete estimated equation for this model.
  Remember in Activity 2 that this looked like:

$$
\hat{y} = 1.5 + 0.4 \times x_1+ 0.434 \times x_2
$$
  
  where $b_0$ and $b_1$ were your model parameter estimates.
  Note that your model here will be different (and have more terms).

5. For each of the estimated parameters (the *y*-intercept and the slopes associated with each explanatory variable - three total), interpret these values in the context of this problem.
  That is, what do they mean for a "non-data" person?
  
*(Intercept): 1.4998522*
*This represents the estimated value of pf_score (personal freedom) when both pf_expression_control and pf_ss (freedom of religion) are 0. In other words, it's the base level of personal freedom in a country with no freedom of expression or freedom of religion.*
*The intercept is statistically significant (p-value < 0.001), meaning this base level of personal freedom is unlikely to have occurred by chance.*

*pf_expression_control: 0.3965278*
*This coefficient indicates that for every one-unit increase in pf_expression_control, the pf_score (personal freedom) increases by 0.3965278, holding pf_ss (freedom of religion) constant.*
*This means that as a country's freedom of expression increases, its overall personal freedom also increases, even after accounting for the effects of freedom of religion.*
*This variable is highly statistically significant (p-value < 0.001), suggesting a strong relationship between freedom of expression and personal freedom.*

*pf_ss: 0.4346730*
*This coefficient suggests that for every one-unit increase in pf_ss (freedom of religion), the pf_score (personal freedom) increases by 0.4346730, holding pf_expression_control constant.*
*So as a country's freedom of religion increases, its overall personal freedom also increases, independent of the effects of freedom of expression.*
*This variable is also highly statistically significant (p-value < 0.001), indicating a strong link between freedom of religion and personal freedom.*

## Challenge: 3-D plots

In *ISL*, the authors provided a 3-D scatterplot with a plane that represents the estimated model.
Do some internet sleuthing to minimally produce a 3-D scatterplot (you do not need to include the plane).
Ideally, this would be something that plays nicely with (looks similar to) `{ggplot2}`.

- Create a new R code chunk, with a descriptive name, and add your code to create this plot.

```{r 3-D plot, message=FALSE, warning=FALSE}
# Load necessary libraries
library(plotly)
library(ggplot2)

# Create 3D scatter plot
plot_ly(hfi_2016, 
        x = ~pf_expression_control, 
        y = ~pf_religion, 
        z = ~pf_ss,
        type = 'scatter3d',
        mode = 'markers') %>%
  layout(scene = list(
    xaxis = list(title = 'pf_expression_control'),
    yaxis = list(title = 'pf_ss'),
    zaxis = list(title = 'pf_score')
  ))
```


After doing this, respond to the following prompt:

6. Compare your 3-D scatterplot and the `GGally::ggpairs` output.
  Comment on the strengths and weaknesses of these two visualizations.
  Do both display on GitHub when you push your work there?
  
*The 3D plot is more interactive, allowing the user to zoom, rotate, and explore the data from different perspectives. This provides a more holistic view of the relationships between the three variables:* pf_expression_control, pf_ss, and pf_score.*
*The 3D visualization can reveal patterns, clusters, and connections that may not be as apparent in a 2D plot, offering a more comprehensive understanding of the data structure.*
*The 3D plot can be more complex to interpret, especially when dealing with large or dense datasets. The overlapping of data points can make it challenging to distinguish individual observations.*
*The 3D nature of the visualization may suffer from depth perception issues when viewed on a 2D medium, such as a computer screen or a printout.*

# Day 2

During Day 1, you fit a model with one quantitative response variable and two quantitative explanatory variables.
Now we look at a model with one quantitative explanatory variable and one qualitative explanatory variable.
We will use the full 2016 dataset for this entire activity.
For the Mini-Competition next week, you will be instructed to use the train/test split process. 

## Fitting the overall model

This is similar to what we have already been doing - fitting our desired model.
For today's activity, we will fit something like:

$$
y = \beta_0 + \beta_1 \times \text{qualitative\\_variable} + \beta_2 \times \text{quantitative\\_variable} + \varepsilon
$$

where $y$, $\text{qualitative\\_variable}$, and $\text{quantitative\\_variable}$ are from `hfi_2016`.
Note that the two explanatory variables can be entered in whatever order.

To help with interpretability, we will focus on qualitative predictor variables with only two levels.
Unfortunately, none of the current `chr` variables have only two levels.
Fortunately, we can create our own.


-In the code chunk below titled `binary-pred`, replace "verbatim" with "r" just before the code chunk title.
-Run your code chunk or knit your document.


```{r binary-pred}
hfi_2016 <- hfi_2016 %>%
  mutate(west_atlantic = if_else(
    region %in% c("North America", "Latin America & the Caribbean"),
    "No",
    "Yes"
  ))
```

7. What is happening in the above code? What new variable did we create? How do you know it is new? What values does it take when?


- In the code chunk below titled `qual-mlr`, replace "verbatim" with "r" just before the code chunk title.
- Run your code chunk or knit your document.

```{r qual-mlr}
# review any visual patterns
hfi_2016 %>% 
  select(pf_score, west_atlantic, pf_expression_control) %>% 
  ggpairs()

#fit the mlr model
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

qual_mod <- lm_spec %>% 
  fit(pf_score ~ west_atlantic + pf_expression_control, data = hfi_2016)

# model output
tidy(qual_mod)
```

When looking at your `ggpairs` output, remember to ask yourself, "does it make sense to include all of these variables?"
Specifically, if you notice that the response variables are highly correlated (collinear), including both does not necessarily add much value as they are essentially saying the same thing.
Note: There are more advanced methods to include the variability within a rater for our model - this is beyond STA 631.
If this sounds of interest to you, explore *generalized estimating equations* (GEE) or *generalized linear mixed models* (GLMM).
However, there are often times when we choose to include variables in our model because it is important to us - for various reasons.
Regardless, I encourage you to keep your readings of *DF* in mind - who will benefit by including this information; who will be hurt by including this information? 

Also, when looking at your model (`tidy`) output, the `term` label for your qualitative explanatory variable look odd.
Answer the following questions:

8. What is the label that R assigned to this explanatory variable `term`?

*The label that R assigned to the explanatory variable is "west_atlanticYes".*

9. What information is represented here?
'Intercept (4.3771413)':
This is the predicted personal freedom (pf_score) for countries that are not in the West Atlantic region and have a pf_expression_control value of 0.

'west_atlanticYes (-0.1024089)':
This shows that on average, countries in the West Atlantic region have a pf_score that is about 0.1 lower than countries not in the West Atlantic region, but this difference is not statistically significant.

'pf_expression_control (0.5401164)':
This indicates that for every 1-unit increase in the expression control measure, the predicted pf_score increases by about 0.54. This relationship is very statistically significant.

10. What information is missing here?

-Sample Size: The total number of observations or data points used to fit the regression model is not provided.

-Standard Errors: The standard errors of the coefficient estimates are not reported. Standard errors indicate the precision of the coefficient estimates and are used to calculate the t-statistics and p-values.

-Variable Descriptions: The descriptions or definitions of the predictor variables, "west_atlantic" and "pf_expression_control", are not included. Providing clear variable descriptions would aid in interpreting the model results.

-Multicollinearity Diagnostics: There is no information on whether the predictor variables exhibit multicollinearity, which can impact the reliability of the coefficient estimates.

-Residual Plots: The output does not include any residual plots, such as a scatter plot of residuals versus fitted values or a normal probability plot of residuals. These diagnostic plots can help assess the validity of the model's assumptions.

-Model Comparison: If this is part of a larger modeling exercise, information on how this model compares to alternative specifications or models would be useful to include.

Your are essentially fitting two models (or $k$ models, where $k$ is the number of levels in your qualitative variable).
From your reading, you learned that R is creating an indicator variable (see p. 83).
If you have 3 levels in your qualitative variable, you would have 2 (3 - 1) indicator variables.
If you have $k$ levels in your qualitative variable, you would have $k - 1$ indicator variables.

The decision for R to call the indicator variable by one of your levels instead of the other has no deeper meaning.
R simply codes the level that comes first alphabetically with a $0$ for your indicator variable.
You can change this reference level of a categorical variable, which is the level that is coded as a 0, using the `relevel` function.
Use `?relevel` to learn more.

11. Write the estimated equation for your MLR model with a qualitative explanatory variable.

$$
\hat{y} = \beta_0 + \beta_1 \times \text{west_atlanticYes} + \beta_2 \times \text{pf_expression_control} + \varepsilon
$$

12. Now, for each level of your qualitative variable, write the simplified equation of the estimated line for that level. 
  Note that if your qualitative variable has two levels, you should have two simplified equations.


When 'west_atlantic' is "Yes":

$$
\hat{y}{Yes} = \beta_0 - \beta_1 + \beta_2 \times \text{pf_expression_control}
$$

When 'west_atlantic' is "No":

$$
\hat{y}{No} = \beta_0 + \beta_1 + \beta_2 \times \text{pf_expression_control} 
$$

Where:

$$
\hat{y}{Yes}
$$
represents the predicted value of the response variable ('pf_score') when 'west_atlantic' is "Yes".
$$
\hat{y}{No}
$$
  represents the predicted value of the response variable ('pf_score') when 'west_atlantic' is "No".
$$
\beta_0, \beta_1 and, \beta_2
$$
are the estimated coefficients from the MLR model.
'pf_expression_control' is the quantitative explanatory variable representing the level of expression and control of personal freedom in a country.
These equations show how the predicted personal freedom score varies with changes in the level of expression and control of personal freedom ('pf_expression_control') for each level of the qualitative variable 'west_atlantic'.


The interpretation of the coefficients (parameter estimates) in multiple regression is slightly different from that of simple regression.
The estimate for the indicator variable reflects how much more a group is expected to be if something has that quality, *while holding all other variables constant*.
The estimate for the quantitative variable reflects how much change in the response variable occurs due to a 1-unit increase in the quantitative variable, *while holding all other variables constant*.

13. Interpret the parameter estimate for the reference level of your categorical variable in the context of your problem.
Page 83 of the text can help here (or have me come chat with you).

Based on the information provided on page 83, the reference level for the categorical variable west_atlantic is "No". The parameter estimate for this reference level reflects the expected change in the response variable pf_score when west_atlantic is at the "No" level, while holding all other variables constant.

The interpretation would be:

For countries where west_atlantic is "No" (i.e., not in the West Atlantic region), the expected value of pf_score is β₀, holding all other variables constant.

The parameter estimate for the reference level "No" of west_atlantic represents the average personal freedom score for countries not in the West Atlantic region, after accounting for the effect of the pf_expression_control variable.

So the interpretation would be something like:

The parameter estimate for the reference level "No" of west_atlantic is -0.102, meaning that countries not in the West Atlantic region are expected to have a personal freedom score that is on average 0.102 units lower than countries in the West Atlantic region, holding the level of expression and control of personal freedom (pf_expression_control) constant.


14. Interpret the parameter estimate for your quantitative variable in the context of your problem.

For each one-unit increase in the `pf_expression_control` score, the personal freedom score (`pf_score`) is expected to increase by approximately 0.540 units on average, controlling for the effect of the categorical variable west_atlantic.


## Challenge: Multiple levels

Below, create a new R code chunk (with a descriptive name) that fits a new model with the same response (`pf_score`) and quantitative explanatory variable (`pf_expression_control`), but now use a qualitative variable with more than two levels (say, `region`) and obtain the `tidy` model output.
How does R appear to handle categorical variables with more than two levels?

```{r more than 2 levels}
# Fitting the model with a qualitative variable with more than two levels
lm_spec_multiple_levels <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

# Fit the model
qual_mod_multiple_levels <- lm_spec_multiple_levels %>% 
  fit(pf_score ~ region + pf_expression_control, data = hfi_2016)

# Display the model output
tidy(qual_mod_multiple_levels)
```

# Day 3

We will explore a MLR model with an interaction between quantitative and qualitative explanatory variables as well as see some other methods to assess the fit of our model.
From the modeling process we came up with as a class, we will now address the "series of important questions that we should consider when performing multiple linear regression" (*ISL* [Section 3.2.2](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf), p. 75):

1. Is at least one of the $p$ predictors $X_1$, $X_2$, $\ldots$, $X_p$ useful in predicting the response $Y$?
2. Do all the predictors help to explain $Y$, or is only a subset of the predictors useful?
3. How well does the model fit the data?
4. Given a set of predictor values, what response value should we predict and how accurate is our prediction?

Note that the text (*ISLR*) covers interactions between two quantitative explanatory variables as well.
By including an interaction term in our model, it may seem like we are relaxing the "additive assumption" a little.
However, the additive assumption is about the coefficients (the $\beta$s) and not the variables.

## Fitting the overall model with $qualitative \times quantitative$ interaction

Recall from Day 2 that you explored the model:

$$
y = \beta_0 + \beta_1 \times \text{qualitative\\_variable} + \beta_2 \times \text{quantitative\\_variable} + \varepsilon
$$

Today we will explore a similar model, except that also includes the interaction between your qualitative and quantitative explanatory variables.
That is,

$$
y = \beta_0 + \beta_1 \times \text{qualitative\\_variable} + \beta_2 \times \text{quantitative\\_variable} + \beta_3 \times ( \text{qualitative\\_variable} \times \text{quantitative\\_variable}) + \varepsilon
$$

- Run all previous code up to this point - you will need your prior dataset of just 2016 observations with the `west_atlantic` variable.
- In the code chunk below titled `int-mlr`, replace "verbatim" with "r" just before the code chunk title.
- Run your code chunk or knit your document.

```{r int-mlr}
# review any visual patterns
hfi_2016 %>% 
  select(pf_score, west_atlantic, pf_expression_control) %>% 
  ggpairs()

#fit the mlr model
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

int_mod <- lm_spec %>% 
  fit(pf_score ~ west_atlantic * pf_expression_control, data = hfi_2016)

# model output
tidy(int_mod)
```

Note that I shortened the model statement using `qualitative * quantitative`, but this can sometimes be confusing to read.
Another way to write the right-hand side of the equation is: `qualitative + quantitative + qualitative * quantitative`.

After doing this, answer the following question:

15. When viewing the `tidy` output, notice that the interaction term is listed as `qualitativelevel:quantitative`.
  Referring back to Day 2 with how R displays qualitative variables, interpret what this syntax means.

$$\beta_3$$
: Represents the additional change in `pf_score` for a one-unit increase in `pf_expression_control` when `west_atlantic` is "Yes" compared to "No".

The qualitativelevel:quantitative term indicates that the effect of the quantitative variable (`pf_expression_control`) on the response variable (`pf_score`) is modified by the qualitative variable (`west_atlantic`).

In simpler terms, it shows that the relationship between `pf_expression_control` and `pf_score` is different depending on whether a region is classified as "Yes" or "No" in the `west_atlantic` variable.


16. Using page 100 of *ISLR* as a reference, if needed, and your work from Day 2, write the simplified equation of the line corresponding to each level of your qualitative explanatory variable.

To write the simplified equations of the line corresponding to each level of the qualitative explanatory variable, we'll break down the model into its components based on the levels of `west_atlantic.` Here’s the model again:

$$\hat{y} = \beta_0 + \beta_1 \times \text{west_atlantic} + \beta_2 \times \text{pf_expression_control} + \beta_3 \times (\text{west_atlantic} \times \text{pf_expression_control})$$

### Simplified Equations for Each Level

For `west_atlantic` = "No" (reference level):
When `west_atlantic` is "No", the term `west_atlantic` and the interaction term `west_atlanticYes`:`pf_expression_control` both drop out because they are zero. Thus, the equation simplifies to:

$$\hat{y}_{\text{No}} = \beta_0 + \beta_2 \times \text{pf_expression_control}$$

Substituting in the values:

$$\hat{y}_{\text{No}} = 5.7213860 + 0.2961044 \times \text{pf_expression_control}$$

For `west_atlantic` = "Yes":
When `west_atlantic` is "Yes", both the `west_atlantic` term and the interaction term `west_atlanticYes`:`pf_expression_control` are included. Thus, the equation is:

$$\hat{y}_{\text{Yes}} = \beta_0 + \beta_1 + \beta_2 \times \text{pf_expression_control} + \beta_3 \times \text{pf_expression_control}$$

Combining the coefficients:

$$\hat{y}_{\text{Yes}} = 5.7213860 + (-1.5979076) + (0.2961044 + 0.2750385) \times \text{pf_expression_control}$$

Simplifying further:

$$\hat{y}_{\text{Yes}} = 4.1234784 + 0.5711429 \times \text{pf_expression_control}$$

### Summary of Simplified Equations

For `west_atlantic` = "No":
$$\hat{y}_{\text{No}} = 5.7213860 + 0.2961044 \times \text{pf_expression_control}$$

For `west_atlantic` = "Yes":
$$\hat{y}_{\text{Yes}} = 4.1234784 + 0.5711429 \times \text{pf_expression_control}$$


17. For two observations with similar values of the quantitative , which level tends to have higher values of the response variable?

Got it, thank you for the detailed explanation. Let me summarize the key points:

-The intercept for the "No" group (5.7213860) is higher than the intercept for the "Yes" group (4.1234784), by a difference of 1.5979076.

-This means that when the quantitative variable `pf_expression_control` is 0, the "No" group has a higher predicted value of the response variable `pf_score`.

-However, the slope for the "Yes" group (0.5711429) is higher than the slope for the "No" group (0.2961044), by a difference of 0.2750385.

-This means that as `pf_expression_control` increases, the `pf_score` increases more rapidly for the "Yes" group compared to the "No" group.

-Therefore, for low values of `pf_expression_control` (close to 0), the "No" group tends to have higher `pf_score` values due to the higher intercept.

-But for higher values of `pf_expression_control`, the "Yes" group will eventually have higher `pf_score` values due to the higher slope.

In conclusion, the level with the higher predicted `pf_score` values depends on the specific value of the `pf_expression_control` variable, with the "No" group being higher at lower values and the "Yes" group being higher at higher values.


18. Like you did in Day 1, assess the fit of this model (no need to do any formal hypothesis testing - we will explore this next).
  How does `int_mod`'s fit compare to `mlr_mod`?
  What did you use to compare these?
  Why?
```{r examining model fit}
# I will refit the Day 1 model here to have them both in one place for comparison
# Fit the models
#mlr_mod <- tidymodels::lm(pf_score ~ west_atlantic + pf_expression_control, data = hfi_2016)
#int_mod <- tidymodels::lm(pf_score ~ west_atlantic * pf_expression_control, data = hfi_2016)

# Extract model summaries
#mlr_mod_summary <- summary(mlr_mod)
#int_mod_summary <- summary(int_mod)

# Extract R-squared and Adjusted R-squared
#mlr_mod_r2 <- mlr_mod_summary$r.squared
#mlr_mod_adj_r2 <- mlr_mod_summary$adj.r.squared
#int_mod_r2 <- int_mod_summary$r.squared
#int_mod_adj_r2 <- int_mod_summary$adj.r.squared

# Display the results
#data.frame(
  #Model = c("MLR", "Interaction MLR"),
  #R2 = c(mlr_mod_r2, int_mod_r2),
  #Adjusted_R2 = c(mlr_mod_adj_r2, int_mod_adj_r2))
```

Recall our brief discussion on how many disciplines are moving away from $p$-values in favor of other methods.
We will explore $p$-values these other methods later this semester, but we will practice our classical methods here.
This is known as an "overall $F$ test" and the hypotheses are:

That (the null) no predictors are useful for the model (i.e., all slopes are equal to zero) versus the alternative that at least one predictor is useful for the model (i.e., at least one slope is not zero).
One way to check this is to build our null model (no predictors) and then compare this to our candidate model (`int_mod`).

- In the code chunk below titled `mod-comp`, replace "verbatim" with "r" just before the code chunk title.
  
```{r mod-comp}
# null model
null_mod <- lm_spec %>% 
fit(pf_score  ~ 1, data = hfi_2016)

anova(
  extract_fit_engine(int_mod),
  extract_fit_engine(null_mod)
)
```

19. Using your background knowledge of $F$ tests, what is the $F$ test statistic and $p$-value for this test?
  Based on an $\alpha = 0.05$ significant level, what should you conclude?

-The F-test statistic for comparing the int_mod and mlr_mod models is 144.6
-The associated p-value is extremely small, reported as < 2.2e-16
-At a significance level of alpha = 0.05, since the p-value is much smaller than 0.05, we reject the null hypothesis.
-This means that at least one of the predictors in the interaction model (west_atlantic * pf_expression_control) is useful for predicting the response variable pf_score.

## Partial slope test - do all predictors help explain $y$?

Assuming that your overall model is significant (at least one predictor is useful), we will continue on.
Continue through these next tasks even if your overall model was not significant.

We could do a similar process to fit a new model while removing one explanatory variable at at time, and using `anova` to compare these models.
However, the `tidy` output also helps here (the `statistic` and `p.value` columns).

For each slope, you are testing if that slope is zero (when including the other variables, the null) or if it is not zero (when including the other variables, the alternative).
Because the interaction term is a combination of the other two variables, we should assess the first.


20. What is the $t$ test statistic and $p$-value associated with this test?
  Based on an $\alpha = 0.05$ significant level, what should you conclude?

-The t-test statistic for the interaction term west_atlanticYes:pf_expression_control is 3.283544
-The associated p-value is 1.262236 × 10^-3
-At a significance level of α = 0.05, since the p-value (1.262236 × 10^-3) is less than α, we reject the null hypothesis.
-The null hypothesis was that the coefficient of the interaction term is zero, meaning there is no interaction effect.
-Therefore, we can conclude that the interaction between west_atlanticYes and pf_expression_control does significantly contribute to explaining the response variable pf_score.

If your interaction term was not significant, you could consider removing it.
Now look at your two non-interaction terms...

21. What are the $t$ test statistic and $p$-value associated with these tests?
  Based on an $\alpha = 0.05$ significant level, what should you conclude about these two predictors?

Let's extract residuals

```{r residuals}
# Extract residuals from the final model
residuals <- residuals(int_mod)
```




You would not need to do (21) if the interaction was significant.
You also should not remove a main variable (non-interaction variable) if the interaction variable remains in your model.

## Residual assessment - how well does the model fit the data?

You have already done this step in past activities by exploring your residuals (Activity 2).
Using your final model from Task 3, assess how well your model fits the data.

